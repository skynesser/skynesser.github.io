---
title: 最小二乘法
date: 2022-04-13 21:12:41
tags:
mathjax: true
---

# 最小二乘法

## 从高数分数预测开始
>给一组数据如下：
>|认真听课的时间|最后的考试分数|
>|-|-|
>|20|40|
>|25|60|
>|30|75|
>|35|80|
>|40|85|
>|45|100|
>我们假设认真听课的时间为$x$，最后的考试分数为$y$。
>并且假设两者间的关系为一个线性函数：
>$y=k*x+b$
>那么我们要怎么通过上面的数据得到一个尽可能精确的模型呢。
## 最小二乘法在问题中的使用
**如何判断我们寻找的函数的精确程度**
>设函数的计算值与真实值之间的差值为$loss$:
>$loss=\sum(k*x+b-y)^{2}$
![请添加图片描述](https://img-blog.csdnimg.cn/66707dbb1b124861a60d2adb043272e4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAdGltZXJfY2F0Y2g=,size_20,color_FFFFFF,t_70,g_se,x_16)

**如何减小误差：**
>我们会发现$loss$是一个关于$k$和$b$的二元函数，而且对于某个变量来说，它们之间是二次函数关系
>![请添加图片描述](https://img-blog.csdnimg.cn/200761036f4a46d282860275ce9cf60e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAdGltZXJfY2F0Y2g=,size_20,color_FFFFFF,t_70,g_se,x_16)
那么我们要寻找的点应该就是上图中的极小值点。
我们可以通过如下公式向极小值点逼近：
$k=k-\alpha*\frac{\partial loss }{\partial k}$
其中$\alpha$为一个常数，又称为学习率，如果我们直接让k减去相应的偏导数，可能减小的数会过大，使得$k$越来越远离极小值点。
我们对$b$也进行相同的处理，这一整个过程即**最小二乘法**。 

## 在代码中的实现(python)

```python
x_list = [20, 25, 30, 35, 40, 45]
y_list = [40, 60, 75, 80, 85, 100]

a = 0.0005# 学习率

k = 1# 给k和b随便赋一个初值
b = 1
# for(int i = 0 ;  i < 3 ; i++)
for epoch in range(100000):# 训练的次数
    loss = 0
    loss_k = 0# k的导数
    loss_b = 0# b的导数
    for i in range(3):
        loss += (k * x_list[i] + b - y_list[i]) * (k * x_list[i] + b - y_list[i])
        loss_k += 2 * x_list[i] * (k * x_list[i] + b - y_list[i])
        loss_b += 2 * (k * x_list[i] + b - y_list[i])

    k -= a * loss_k
    b -= a * loss_b

    if epoch % 100 == 0:
        print("loss = %f,loss_b = %f,loss_k = %f,k = %f,b = %f" % (loss, loss_b, loss_k, k, b))
```
**效果图：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/1cc69c63bb4f4ec9a692f69906725615.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAdGltZXJfY2F0Y2g=,size_20,color_FFFFFF,t_70,g_se,x_16)

